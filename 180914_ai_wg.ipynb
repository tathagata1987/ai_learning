{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Working Group\n",
    "#### 9/14/18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal\n",
    "\n",
    "* Generate ideas and create AI use cases that can add value\n",
    "* Learn learn new things and have some fun\n",
    "\n",
    "### What are we doing in this session?\n",
    "* A demo of deep learning concepts and how to develop such models in 1h - very ambitious!\n",
    "* Deep learning is simply neural networks with hidden layers and different configurations\n",
    "* Predictive analytics is converging to AI, and nowadyas the terms \"AI\" and \"deep learning\" are used interchangeably\n",
    "\n",
    "### Setting expectations\n",
    "\n",
    "* It's about implementing use cases, actually coding and doing something\n",
    "* It's not about debating AI/ML definitions, opinions or philosophies\n",
    "* It's ultimately for those who love to innovate and to code\n",
    "* The field is in general for practitioners, a lot of steps do not have a \"why\" theoretically (theory comes after practice)\n",
    "* For those less familiar with AI or Python, learning curve will be steep but very doable\n",
    "* There are below more references than one digest in half a year, deep dives are left to you according to your interests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rn\n",
    "import math\n",
    "from math import pi\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from numpy import *\n",
    "import numpy as np\n",
    "np.random.seed(1212)\n",
    "import scipy as sc\n",
    "from IPython.display import display, Image\n",
    "np.random.seed(9939)\n",
    "rn.seed(9939)\n",
    "tf.set_random_seed(9939)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/gpu:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/cpu:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 4829691669827660526, name: \"/gpu:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 384237568\n",
       " locality {\n",
       "   bus_id: 1\n",
       " }\n",
       " incarnation: 5849925935853155125\n",
       " physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:07.0\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neural network is composed of units called neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/10/13164412/neuron.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/10/13164412/neuron.png\",width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neurons are defined by their respective \"activation functions.\" A well-known activation function is the sigmoid, which in fact is the inverve function of the logit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://neuralnetworksanddeeplearning.com/images/tikz29.png\" width=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"http://neuralnetworksanddeeplearning.com/images/tikz29.png\",width=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{eqnarray} \n",
    "  \\sigma(z) \\equiv \\frac{1}{1+e^{-z}}\n",
    "\\end{eqnarray}\n",
    "\n",
    "\\begin{eqnarray} \n",
    "  \\sigma(z) \\equiv \\frac{1}{1+\\exp(-\\sum_j w_j x_j-b)}\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://nathanbrixius.files.wordpress.com/2016/06/sigmoid_thumb.png?w=636&h=480\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://nathanbrixius.files.wordpress.com/2016/06/sigmoid_thumb.png?w=636&h=480\",width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other types of activation functions, with the most widely use in deep learning being the ReLu function:\n",
    "\n",
    "\\begin{eqnarray} \n",
    "  f(x)=\\text{max}(0,x)\n",
    "\\end{eqnarray}\n",
    "\n",
    "https://en.wikipedia.org/wiki/Rectifier_(neural_networks)\n",
    "\n",
    "https://stats.stackexchange.com/questions/226923/why-do-we-use-relu-in-neural-networks-and-how-do-we-use-it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/10/17160725/relu-300x300.png\" width=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/10/17160725/relu-300x300.png\",width=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an exposition of activation functions, see below:\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2017/10/fundamentals-deep-learning-activation-functions-when-to-use-them/\n",
    "\n",
    "Play with neurons and activations here:\n",
    "\n",
    "http://neuralnetworksanddeeplearning.com/chap4.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks can be formed by combining neurons in certain configurations. A so-called \"fully-connected\" network is an architecture such that layers of neurons are combined in a serialized manner, with an input layer, an output layer and hidden layers in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://neuralnetworksanddeeplearning.com/images/tikz11.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"http://neuralnetworksanddeeplearning.com/images/tikz11.png\",width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network we will apply in one of the examples (MNIST handwritten digits) looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://neuralnetworksanddeeplearning.com/images/tikz12.png\" width=\"600\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"http://neuralnetworksanddeeplearning.com/images/tikz12.png\",width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11935"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "784*15+15+15*10+10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a neural network is simply an optimization problem where one aims to find the parameters (weights, biases) that minimize a certain cost function. The most common function adopted for classification problems in deep learning is the cross-entropy:\n",
    "\n",
    "\\begin{eqnarray} \n",
    "  C = -\\frac{1}{n} \\sum_x \\left[y \\ln \\bar{y} + (1-y ) \\ln (1-\\bar{y}) \\right]\n",
    "\\end{eqnarray}\n",
    "\n",
    "The method that has proven very successful and promoted the explosion of deep learning applications is called Stochastic Gradient Descent (SGD)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic Gradient Descent (SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimization problem in deep learning is in fact a minimization problem. We want to find the parameters that give the minimum value of the cost function (cross-entropy). One learns in a basic course in calculus that the gradient (or first derivative) of the function may be used to point in the direction of where the minimum of that function is.\n",
    "\n",
    "In fact, if we multiply the current value of the parameter by the negative of the gradient times a constant (learning rate), we move one step toward the minimum of the function:\n",
    "\n",
    "\\begin{eqnarray} \n",
    "  x = x - \\alpha \\nabla_x E[J(x)]\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/800/1*HrFZV7pKPcc5dzLaWvngtQ.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://cdn-images-1.medium.com/max/800/1*HrFZV7pKPcc5dzLaWvngtQ.png\",width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easy enough for a simple convex function.\n",
    "\n",
    "What if the function looks like this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://davidmatablog.files.wordpress.com/2017/08/localminima.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://davidmatablog.files.wordpress.com/2017/08/localminima.png\",width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And what if the function looks like this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://www1.lsbu.ac.uk/water/images/dry_surface.gif\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"http://www1.lsbu.ac.uk/water/images/dry_surface.gif\",width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/600/1*msObu3xbQzSnKvtCW2z6YQ.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://cdn-images-1.medium.com/max/600/1*msObu3xbQzSnKvtCW2z6YQ.png\",width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical approach in deep learning is to iterativelly and randomly (stochastic) select small samples of the input data (mini-batches), compute the gradient of the cost function to each parameter and average it out across the mini-batch, and apply it to move one step in the parameter space. This is done mini-batch by mini-batch until all data points are scanned, which completes one epoch. This is done for many epochs until the \"ground state\" is achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/800/1*Y2KPVGrVX9MQkeI8Yjy59Q.gif\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://cdn-images-1.medium.com/max/800/1*Y2KPVGrVX9MQkeI8Yjy59Q.gif\",width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In effect, the cost function in deep learning has no \"global minimum\" but various local minima around the ground state. A gradient-type of minimization reaches one of these local minima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://www.skynet.ie/~stephen/reports/images/energy-landscape.gif\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"http://www.skynet.ie/~stephen/reports/images/energy-landscape.gif\",width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are good references of SGD and SGD-type methods applied in deep learning:\n",
    "\n",
    "http://ufldl.stanford.edu/tutorial/supervised/OptimizationStochasticGradientDescent/\n",
    "\n",
    "https://towardsdatascience.com/gradient-descent-algorithms-and-adaptive-learning-rate-adjustment-methods-79c701b086be\n",
    "\n",
    "https://medium.com/@ramrajchandradevan/the-evolution-of-gradient-descend-optimization-algorithm-4106a6702d39"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backpropagation is one of the most important discoveries (or re-discovery) of modern AI. One thing is designing an algorithm that uses gradients in traning the networks. Another is having an efficient way of even being able to compute these gradients for each of the many paramters in the network. This is what backpropagation achieves. Here is one of the best online resources on backpropagation:\n",
    "\n",
    "http://colah.github.io/posts/2015-08-Backprop/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equation\n",
    "\n",
    "\\begin{equation}\n",
    "e=(a+b)*(b+1)\n",
    "\\end{equation}\n",
    "\n",
    "may be represented as a graph:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "c=a+b,\\\\\n",
    "d=b+1,\\\\\n",
    "e=c∗d.\n",
    "\\end{eqnarray}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://colah.github.io/posts/2015-08-Backprop/img/tree-def.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"http://colah.github.io/posts/2015-08-Backprop/img/tree-def.png\",width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we want the gradient of the cost function 'e' to the parameter 'b'. This is trivial throught the chain rule moving forward from 'b' all the way to 'e' through the graph above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://colah.github.io/posts/2015-08-Backprop/img/tree-eval-derivs.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"http://colah.github.io/posts/2015-08-Backprop/img/tree-eval-derivs.png\",width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, imagine doing this for all thousands (millions, billions) of parameters in a deep neural network? It's not feasible!\n",
    "\n",
    "What about if we perform this exercise by going backwards, from 'e' to 'b'? This is what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://colah.github.io/posts/2015-08-Backprop/img/tree-backprop.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"http://colah.github.io/posts/2015-08-Backprop/img/tree-backprop.png\",width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In one single pass, we are able to compute the gradient of 'e' to every single node in the graph!\n",
    "\n",
    "This is already buit-in every deep learning package in use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow is the tool of choice for the exercises proposed here. It is the most widely used deep learning package, although there are nowadays many other competing and emerging packages (Caffe, PyTorch, etc).\n",
    "\n",
    "We are not going through the details of coding with TensorFlow now, but do take a look at these references below. The best way to learn TensorFlow (any programming for that matter) is by doing!\n",
    "\n",
    "https://www.tensorflow.org/tutorials/\n",
    "\n",
    "https://arxiv.org/pdf/1610.01178.pdf\n",
    "\n",
    "https://www.youtube.com/watch?v=MotG3XI2qSs\n",
    "\n",
    "https://developer.telerik.com/topics/machine-learning/getting-started-tensorflow/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST\n",
    "\n",
    "http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST is a go-to dataset for demonstration of deep learning techniques, applications, research, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../mnist/train-images-idx3-ubyte.gz\n",
      "Extracting ../mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ../mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Data was downloaded from: http://yann.lecun.com/exdb/mnist/\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('../mnist', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32),\n",
       " array([[ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.next_batch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32),\n",
       " array([[ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.validation.next_batch(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32),\n",
       " array([[ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.next_batch(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.227451  ,  0.47450984,  0.94117653,\n",
       "        0.99215692,  0.57647061,  0.37254903,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.04705883,  0.41960788,  0.69411767,\n",
       "        0.96862751,  0.98823535,  0.98823535,  0.98823535,  0.98823535,\n",
       "        0.77647066,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.07843138,  0.36862746,\n",
       "        0.70588237,  0.98823535,  0.98823535,  0.99215692,  0.98823535,\n",
       "        0.98823535,  0.98823535,  0.98823535,  0.89019614,  0.16470589,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.10196079,  0.82352948,  0.98823535,  0.98823535,\n",
       "        0.98823535,  0.99215692,  0.6901961 ,  0.67450982,  0.77254909,\n",
       "        0.98823535,  0.77647066,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.62352943,\n",
       "        0.98823535,  0.98823535,  0.98823535,  0.57254905,  0.20784315,\n",
       "        0.01176471,  0.        ,  0.23137257,  0.9333334 ,  0.50196081,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.14117648,  0.86666673,  0.98823535,  0.98823535,\n",
       "        0.56078434,  0.12156864,  0.        ,  0.        ,  0.07843138,\n",
       "        0.37647063,  0.9333334 ,  0.9333334 ,  0.72941178,  0.4039216 ,\n",
       "        0.20000002,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.04313726,\n",
       "        0.77254909,  0.98823535,  0.98823535,  0.41568631,  0.        ,\n",
       "        0.07843138,  0.16078432,  0.74117649,  0.98823535,  0.98823535,\n",
       "        0.98823535,  0.98823535,  0.98823535,  0.85098046,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.09803922,  0.49803925,  0.98823535,\n",
       "        0.98823535,  0.74901962,  0.38431376,  0.80000007,  0.98823535,\n",
       "        0.98823535,  0.98823535,  0.98823535,  0.98823535,  0.98823535,\n",
       "        0.98823535,  0.6901961 ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.09019608,  0.80784321,  0.98823535,  0.98823535,\n",
       "        0.98823535,  0.99215692,  0.98823535,  0.98823535,  0.98823535,\n",
       "        0.9450981 ,  0.82352948,  0.41568631,  0.41568631,  0.17647059,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.1137255 ,\n",
       "        0.84313732,  0.98823535,  0.98823535,  0.98823535,  0.99215692,\n",
       "        0.98823535,  0.51764709,  0.4666667 ,  0.09803922,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.10196079,  0.82745105,  0.99215692,\n",
       "        0.99215692,  0.99215692,  1.        ,  0.99215692,  0.38039219,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.1137255 ,\n",
       "        0.81568635,  0.98823535,  0.98823535,  0.98823535,  0.98823535,\n",
       "        0.99215692,  0.98823535,  0.38039219,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.11764707,  0.80784321,  0.98823535,  0.98823535,\n",
       "        0.98823535,  0.98823535,  0.98823535,  0.99215692,  0.98823535,\n",
       "        0.56862748,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.75686282,\n",
       "        0.98823535,  0.98823535,  0.98823535,  0.89803928,  0.15294118,\n",
       "        0.59215689,  0.99215692,  0.98823535,  0.92941183,  0.29803923,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.43137258,  0.95686281,  0.98823535,  0.98823535,\n",
       "        0.9450981 ,  0.37647063,  0.        ,  0.10980393,  0.85490203,\n",
       "        0.98823535,  0.98823535,  0.67450982,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.09019608,  0.63137257,\n",
       "        0.98823535,  0.98823535,  0.9450981 ,  0.65490198,  0.        ,\n",
       "        0.        ,  0.        ,  0.33333334,  0.96078438,  0.98823535,\n",
       "        0.90588242,  0.15294118,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.50196081,  0.98823535,  0.98823535,  0.98823535,\n",
       "        0.81176478,  0.16078432,  0.16078432,  0.16078432,  0.43529415,\n",
       "        0.99215692,  0.98823535,  0.98823535,  0.85490203,  0.17254902,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.60784316,\n",
       "        0.98823535,  0.98823535,  0.98823535,  0.98823535,  0.98823535,\n",
       "        0.98823535,  0.98823535,  0.98823535,  0.99215692,  0.98823535,\n",
       "        0.98823535,  0.43137258,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.17647059,  0.90196085,  0.98823535,\n",
       "        0.98823535,  0.98823535,  0.98823535,  0.98823535,  0.98823535,\n",
       "        0.98823535,  0.99215692,  0.93725497,  0.74117649,  0.06666667,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.36862746,  0.98823535,  0.98823535,  0.98823535,\n",
       "        0.98823535,  0.98823535,  0.96078438,  0.4666667 ,  0.47058827,\n",
       "        0.02352941,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = mnist.train.next_batch(1)[0][0]\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x3efff58a26d8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x3ffeef3b6e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.gray()\n",
    "plt.imshow(np.reshape(img,[28,28]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.cntk.ai/jup/cntk103a_MNIST_input.png\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatening image\n",
    "Image(url=\"https://www.cntk.ai/jup/cntk103a_MNIST_input.png\",width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Fully-Connected Network MNIST\n",
    "\n",
    "https://dataplatform.ibm.com/analytics/notebooks/91440c8b-0bfb-471e-b04e-235e4d9f510d/view?access_token=fb4380415a903111e26cec3bd95d8ba91a04746185c866fecde9d36643fa5585"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hello, Tensor World!\n",
    "Let’s analyze the Hello World script you ran. For reference, I’ve added the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello World!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create TensorFlow object called hello_constant\n",
    "hello_constant = tf.constant('Hello World!')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Run the tf.constant operation in the session\n",
    "    output = sess.run(hello_constant)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hello_constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor\n",
    "\n",
    "In TensorFlow, data isn’t stored as integers, floats, or strings. These values are encapsulated in an object called a tensor. In the case of ```hello_constant = tf.constant('Hello World!')```, ```hello_constant``` is a 0-dimensional string tensor, but tensors come in a variety of sizes as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A is a 0-dimensional int32 tensor\n",
    "A = tf.constant(1234) \n",
    "# B is a 1-dimensional int32 tensor\n",
    "B = tf.constant([ [123,456,789] ]) \n",
    " # C is a 2-dimensional int32 tensor\n",
    "C = tf.constant([ [123,456,789], [222,333,444] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session\n",
    "\n",
    "TensorFlow’s api is built around the idea of a computational graph, a way of visualizing a mathematical process. Let’s take the TensorFlow code you ran and turn that into a graph:\n",
    "<img src=\"https://d17h27t6h515a5.cloudfront.net/topher/2016/October/580feadb_session/session.png\" alt=\"\" class=\"index--image--1xyr4\" style=\"height: 312.419px; width: 539px;\">\n",
    "A \"TensorFlow Session\", as shown above, is an environment for running a graph. The session is in charge of allocating the operations to GPU(s) and/or CPU(s), including remote machines. Let’s see how you use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello World!'\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    output = sess.run(hello_constant)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code has already created the tensor, ```hello_constant```, from the previous lines. The next step is to evaluate the tensor in a session.\n",
    "\n",
    "The code creates a session instance, sess, using ```tf.Session```,. The ```sess.run()```, function then evaluates the tensor and returns the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST For ML Beginners\n",
    "\n",
    "This tutorial is intended for readers who are new to both machine learning and TensorFlow. If you already know what MNIST is, and what softmax (multinomial logistic) regression is, you might prefer this faster paced tutorial. Be sure to install TensorFlow before starting either tutorial.\n",
    "\n",
    "When one learns how to program, there's a tradition that the first thing you do is print \"Hello World.\" Just like programming has Hello World, machine learning has MNIST.\n",
    "\n",
    "MNIST is a simple computer vision dataset. It consists of images of handwritten digits like these:\n",
    "<img style=\"width:80%\" src=\"https://www.tensorflow.org/images/MNIST.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also includes labels for each image, telling us which digit it is. For example, the labels for the above images are 5, 0, 4, and 1.\n",
    "\n",
    "In this tutorial, we're going to train a model to look at images and predict what digits they are. Our goal isn't to train a really elaborate model that achieves state-of-the-art performance -- although we'll give you code to do that later! -- but rather to dip a toe into using TensorFlow. As such, we're going to start with a very simple model, called a Softmax Regression.\n",
    "\n",
    "The actual code for this tutorial is very short, and all the interesting stuff happens in just three lines. However, it is very important to understand the ideas behind it: both how TensorFlow works and the core machine learning concepts. Because of this, we are going to very carefully work through the code.\n",
    "\n",
    "#### About this tutorial\n",
    "\n",
    "This tutorial is an explanation, line by line, of what is happening in the mnist_softmax.py code.\n",
    "\n",
    "You can use this tutorial in a few different ways, including:\n",
    "\n",
    "- Copy and paste each code snippet, line by line, into a Python environment as you read through the explanations of each line.\n",
    "- Run the entire mnist_softmax.py Python file either before or after reading through the explanations, and use this tutorial to understand the lines of code that aren't clear to you.\n",
    "What we will accomplish in this tutorial:\n",
    "\n",
    "- Learn about the MNIST data and softmax regressions\n",
    "- Create a function that is a model for recognizing digits, based on looking at every pixel in the image\n",
    "- Use Tensorflow to train the model to recognize digits by having it \"look\" at thousands of examples (and run our first Tensorflow session to do so)\n",
    "- Check the model's accuracy with our test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We describe these interacting operations by manipulating symbolic variables. Let's create one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://ml4a.github.io/images/figures/mnist_1layer.png\" width=\"600\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://ml4a.github.io/images/figures/mnist_1layer.png\",width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x isn't a specific value. It's a placeholder, a value that we'll input when we ask TensorFlow to run a computation. We want to be able to input any number of MNIST images, each flattened into a 784-dimensional vector. We represent this as a 2-D tensor of floating-point numbers, with a shape [None, 784]. (Here None means that a dimension can be of any length.)\n",
    "\n",
    "We also need the weights and biases for our model. We could imagine treating these like additional inputs, but TensorFlow has an even better way to handle it: Variable. A Variable is a modifiable tensor that lives in TensorFlow's graph of interacting operations. It can be used and even modified by the computation. For machine learning applications, one generally has the model parameters be Variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create these Variables by giving tf.Variable the initial value of the Variable: in this case, we initialize both W and b as tensors full of zeros. Since we are going to learn W and b, it doesn't matter very much what they initially are.\n",
    "\n",
    "Notice that W has a shape of [784, 10] because we want to multiply the 784-dimensional image vectors by it to produce 10-dimensional vectors of evidence for the difference classes. b has a shape of [10] so we can add it to the output.\n",
    "\n",
    "We can now implement our model. It only takes one line to define it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training\n",
    "\n",
    "In order to train our model, we need to define what it means for the model to be good. Well, actually, in machine learning we typically define what it means for a model to be bad. We call this the cost, or the loss, and it represents how far off our model is from our desired outcome. We try to minimize that error, and the smaller the error margin, the better our model is.\n",
    "\n",
    "To implement cross-entropy we need to first add a new placeholder to input the correct answers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can implement the cross-entropy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know what we want our model to do, it's very easy to have TensorFlow train it to do so. Because TensorFlow knows the entire graph of your computations, it can automatically use the backpropagation algorithm to efficiently determine how your variables affect the loss you ask it to minimize. Then it can apply your choice of optimization algorithm to modify the variables and reduce the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we ask TensorFlow to minimize cross_entropy using the gradient descent algorithm with a learning rate of 0.5. Gradient descent is a simple procedure, where TensorFlow simply shifts each variable a little bit in the direction that reduces the cost. But TensorFlow also provides many other optimization algorithms: using one is as simple as tweaking one line.\n",
    "\n",
    "What TensorFlow actually does here, behind the scenes, is to add new operations to your graph which implement backpropagation and gradient descent. Then it gives you back a single operation which, when run, does a step of gradient descent training, slightly tweaking your variables to reduce the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to assess the model performance, we need figure out where we predicted the correct label. tf.argmax is an extremely useful function which gives you the index of the highest entry in a tensor along some axis. For example, tf.argmax(y,1) is the label our model thinks is most likely for each input, while tf.argmax(y_,1) is the correct label. We can use tf.equal to check if our prediction matches the truth.\n",
    "\n",
    "Let's train the model ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.11, test accuracy 0.098\n",
      "step 500, training accuracy 0.94, test accuracy 0.9122\n",
      "step 1000, training accuracy 0.92, test accuracy 0.9193\n",
      "step 1500, training accuracy 0.91, test accuracy 0.9167\n",
      "step 2000, training accuracy 0.89, test accuracy 0.9235\n",
      "step 2500, training accuracy 0.93, test accuracy 0.9207\n",
      "step 3000, training accuracy 0.9, test accuracy 0.9211\n",
      "step 3500, training accuracy 0.85, test accuracy 0.923\n",
      "step 4000, training accuracy 0.91, test accuracy 0.9213\n",
      "step 4500, training accuracy 0.96, test accuracy 0.9229\n",
      "step 5000, training accuracy 0.97, test accuracy 0.9225\n",
      "step 5500, training accuracy 0.98, test accuracy 0.9217\n",
      "step 6000, training accuracy 0.96, test accuracy 0.9231\n",
      "step 6500, training accuracy 0.92, test accuracy 0.9248\n",
      "step 7000, training accuracy 0.92, test accuracy 0.9181\n",
      "step 7500, training accuracy 0.94, test accuracy 0.9244\n",
      "step 8000, training accuracy 0.89, test accuracy 0.9242\n",
      "step 8500, training accuracy 0.95, test accuracy 0.9231\n",
      "step 9000, training accuracy 0.92, test accuracy 0.9242\n",
      "step 9500, training accuracy 0.95, test accuracy 0.924\n",
      "final test accuracy 0.9198\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "  if i%500 == 0:\n",
    "    train_accuracy = accuracy.eval(feed_dict={x:batch_xs,y_:batch_ys})\n",
    "    test_accuracy = accuracy.eval(feed_dict={x:mnist.test.images,y_:mnist.test.labels})\n",
    "    print(\"step %d, training accuracy %g, test accuracy %g\"%(i,train_accuracy,test_accuracy))\n",
    "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "test_accuracy = accuracy.eval(feed_dict={x:mnist.test.images,y_:mnist.test.labels})\n",
    "print(\"final test accuracy %g\"%test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## TensorFlow Multilayer CNN MNIST\n",
    "\n",
    "In the tutorial above, with a single layer fully-connected network and only 10,000 iterations ran extremely fast and had an accurary of about 92%.\n",
    "\n",
    "The goal now is to follow the step-by-step guide from TensorFlow's wesite to build a multilayer CNN:\n",
    "\n",
    "https://www.tensorflow.org/tutorials/estimators/cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Getting 92% accuracy on MNIST is bad. It's almost embarrassingly bad. In this section, we'll fix that, jumping from a very simple model to something moderately sophisticated: a small convolutional neural network. This will get us to around 99% accuracy -- not state of the art, but respectable.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolution and Pooling\n",
    "\n",
    "TensorFlow also gives us a lot of flexibility in convolution and pooling operations. How do we handle the boundaries? What is our stride size? In this example, we're always going to choose the vanilla version. Our convolutions uses a stride of one and are zero padded so that the output is the same size as the input. Our pooling is plain old max pooling over 2x2 blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.cntk.ai/jup/cntk103d_conv2d_final.gif\" width=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://www.cntk.ai/jup/cntk103d_conv2d_final.gif\",width=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.cntk.ai/jup/cntk103d_filterset_v2.png\" width=\"800\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convolution\n",
    "Image(url=\"https://www.cntk.ai/jup/cntk103d_filterset_v2.png\",width=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is an example of pooling with stride 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.cntk.ai/jup/cntk103d_same_padding_no_strides.gif\" width=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://www.cntk.ai/jup/cntk103d_same_padding_no_strides.gif\",width=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.katacoda.com/basiafusinska/courses/deep-learning-with-tensorflow/tensorflow-mnist-convolution/assets/convolution.png\" width=\"800\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://www.katacoda.com/basiafusinska/courses/deep-learning-with-tensorflow/tensorflow-mnist-convolution/assets/convolution.png\",width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.cntk.ai/jup/c103d_max_pooling.gif\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max Pooling\n",
    "Image(url=\"https://www.cntk.ai/jup/c103d_max_pooling.gif\",width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"720\"\n",
       "            height=\"400\"\n",
       "            src=\"https://www.youtube.com/embed/AgkfIQ4IGaM\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x3efff58883c8>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('AgkfIQ4IGaM',width=720,height=400)\n",
    "# See video fast forward to 1:30min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight Initialization\n",
    "\n",
    "To create this model, we're going to need to create a lot of weights and biases. One should generally initialize weights with a small amount of noise for symmetry breaking, and to prevent 0 gradients. Since we're using ReLU neurons, it is also good practice to initialize them with a slightly positive initial bias to avoid \"dead neurons\". Instead of doing this repeatedly while we build the model, let's create two handy functions to do it for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Convolutional Layer\n",
    "\n",
    "We can now implement our first layer. It will consist of convolution, followed by max pooling. The convolution will compute 32 features for each 5x5 patch. Its weight tensor will have a shape of [5, 5, 1, 32]. The first two dimensions are the patch size, the next is the number of input channels, and the last is the number of output channels. We will also have a bias vector with a component for each output channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply the layer, we first reshape x to a 4d tensor, with the second and third dimensions corresponding to image width and height, and the final dimension corresponding to the number of color channels.\n",
    "\n",
    "Actually, we'll create the x placeholder directly as we did not run the first tutorial, so there is no x yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "x_image = tf.reshape(x, [-1,28,28,1])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then convolve x_image with the weight tensor, add the bias, apply the ReLU function, and finally max pool. The max_pool_2x2 method will reduce the image size to 14x14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Convolutional Layer\n",
    "\n",
    "In order to build a deep network, we stack several layers of this type. The second layer will have 64 features for each 5x5 patch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Densely Connected Layer\n",
    "\n",
    "Now that the image size has been reduced to 7x7, we add a fully-connected layer with 1024 neurons to allow processing on the entire image. We reshape the tensor from the pooling layer into a batch of vectors, multiply by a weight matrix, add a bias, and apply a ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout\n",
    "\n",
    "To reduce overfitting, we will apply dropout before the readout layer. We create a placeholder for the probability that a neuron's output is kept during dropout. This allows us to turn dropout on during training, and turn it off during testing. TensorFlow's tf.nn.dropout op automatically handles scaling neuron outputs in addition to masking them, so dropout just works without any additional scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Readout Layer\n",
    "\n",
    "Finally, we add a layer, just like for the one layer softmax regression above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and Evaluate the Model\n",
    "\n",
    "How well does this model do? To train and evaluate it we will use code that is nearly identical to that for the simple one layer SoftMax network above. The differences are that:\n",
    "\n",
    "* We will replace the steepest gradient descent optimizer with the more sophisticated ADAM optimizer.\n",
    "\n",
    "* We will include the additional parameter keep_prob in feed_dict to control the dropout rate.\n",
    "\n",
    "* We will add logging to every 100th iteration in the training process.\n",
    "\n",
    "Feel free to go ahead and run this code, but it does 20,000 training iterations and may take a while (possibly up to half an hour), depending on your processor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "prob = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, train accuracy 0.1, test accuracy 0.0945\n",
      "step 500, train accuracy 0.95, test accuracy 0.943\n",
      "step 1000, train accuracy 0.99, test accuracy 0.9656\n",
      "step 1500, train accuracy 0.95, test accuracy 0.974\n",
      "step 2000, train accuracy 0.98, test accuracy 0.9785\n",
      "step 2500, train accuracy 0.97, test accuracy 0.9808\n",
      "step 3000, train accuracy 0.97, test accuracy 0.9802\n",
      "step 3500, train accuracy 1, test accuracy 0.984\n",
      "step 4000, train accuracy 0.98, test accuracy 0.984\n",
      "step 4500, train accuracy 0.99, test accuracy 0.9862\n",
      "step 5000, train accuracy 0.99, test accuracy 0.9859\n",
      "step 5500, train accuracy 0.99, test accuracy 0.9873\n",
      "step 6000, train accuracy 0.99, test accuracy 0.9886\n",
      "step 6500, train accuracy 0.98, test accuracy 0.9861\n",
      "step 7000, train accuracy 1, test accuracy 0.9875\n",
      "step 7500, train accuracy 1, test accuracy 0.986\n",
      "step 8000, train accuracy 1, test accuracy 0.9878\n",
      "step 8500, train accuracy 0.99, test accuracy 0.9883\n",
      "step 9000, train accuracy 1, test accuracy 0.9881\n",
      "step 9500, train accuracy 1, test accuracy 0.9893\n",
      "step 10000, train accuracy 1, test accuracy 0.9894\n",
      "step 10500, train accuracy 1, test accuracy 0.9891\n",
      "step 11000, train accuracy 1, test accuracy 0.9908\n",
      "step 11500, train accuracy 1, test accuracy 0.9891\n",
      "step 12000, train accuracy 0.99, test accuracy 0.9901\n",
      "step 12500, train accuracy 1, test accuracy 0.9898\n",
      "step 13000, train accuracy 1, test accuracy 0.9895\n",
      "step 13500, train accuracy 0.99, test accuracy 0.9906\n",
      "step 14000, train accuracy 1, test accuracy 0.9908\n",
      "step 14500, train accuracy 0.99, test accuracy 0.9896\n",
      "step 15000, train accuracy 1, test accuracy 0.9908\n",
      "step 15500, train accuracy 1, test accuracy 0.9896\n",
      "step 16000, train accuracy 1, test accuracy 0.9898\n",
      "step 16500, train accuracy 1, test accuracy 0.9909\n",
      "step 17000, train accuracy 1, test accuracy 0.9914\n",
      "step 17500, train accuracy 1, test accuracy 0.9905\n",
      "step 18000, train accuracy 1, test accuracy 0.9911\n",
      "step 18500, train accuracy 1, test accuracy 0.9911\n",
      "step 19000, train accuracy 1, test accuracy 0.9901\n",
      "step 19500, train accuracy 1, test accuracy 0.9902\n",
      "final test accuracy 0.9919\n"
     ]
    }
   ],
   "source": [
    "for i in range(20000):\n",
    "  batch = mnist.train.next_batch(100)\n",
    "  if i%500 == 0:\n",
    "    train_accuracy = accuracy.eval(feed_dict={x:batch[0],y_: batch[1],keep_prob:prob})\n",
    "    test_accuracy = accuracy.eval(feed_dict={x:mnist.test.images,y_:mnist.test.labels,keep_prob:prob})\n",
    "    print(\"step %d, train accuracy %g, test accuracy %g\"%(i,train_accuracy,test_accuracy))\n",
    "  train_step.run(feed_dict={x:batch[0],y_:batch[1],keep_prob:prob})\n",
    "test_accuracy = accuracy.eval(feed_dict={x:mnist.test.images,y_:mnist.test.labels,keep_prob:prob})\n",
    "print(\"final test accuracy %g\"%test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other References\n",
    "\n",
    "#### General\n",
    "\n",
    "https://medium.com/\n",
    "\n",
    "#### Python\n",
    "\n",
    "https://cognitiveclass.ai/courses/python-for-data-science/\n",
    "\n",
    "#### Deep Learning\n",
    "\n",
    "http://course.fast.ai/\n",
    "\n",
    "http://wiki.fast.ai/index.php/Main_Page\n",
    "\n",
    "http://deeplearning.stanford.edu/tutorial/\n",
    "\n",
    "https://www.deeplearning.ai/\n",
    "\n",
    "https://www.kaggle.com/getting-started/37999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stay tuned, participate!\n",
    "\n",
    "Follow posts and communications on:\n",
    "\n",
    "http://jive.ms.com/groups/mrm-ai\n",
    "\n",
    "Create an idea for AI use cases on the **\"Idea\"** button of the Jive website. These ideas will be brought to future sessions of the group and potentially become real projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
